\chapter{Проведение экспериментов} \label{cha:experiments}
% QUESTION НУЖНО ЛИ ПЕРЕРИСОВЫВАТЬ КАРТИНКИ? А ССЫЛКИ НА КАРТИНКИ?

\section{Используемые инструменты}
% QUESTION: нужно это вообще?
Разработка велась на языке программирования \textit{Python 3.8}.
% QUESTION: правильно сослался?
Реализация нейронных сетей и оценка качества выполнены с помощью библиотек \textit{PyTorch} \cite{pytorch_lib}, \textit{transformers} и \textit{evaluate} от проекта \textit{HuggingFace} \cite{huggingface_transformers}.
Предобученные модели получены из \textit{HuggingFaceHub}, открытого репозиторя моделей и наборов данных.
Обучение выполнялось на видеокарте Nvidia T4.

\section{Метрики качества}
% QUESTION: тут цитаты нужно сделать? а что конкретно за веса, что взяты из хаггингфейса нужно сказать? если да, то как? а на берт нужно сослаться?

Для оценки качества алгоритма будут использоваться следующие метрики:
\begin{itemize}
    \item SacreBLEU \cite{sacrebleu};
    \item METEOR \cite{meteor};
    \item 
    Style Score -- дообученный с помощью параметро-эффективного метода LoRA \cite{lora} на собранном наборе данных классификатор стиля.
    В качестве изначальных весов взят \texttt{xlm-roberta-base}. Качество классификатора:
    \texttt{Accuracy}: 86\%,
    \texttt{F-1}: 86\%,
    \texttt{Precision}: 91\%,
    \texttt{Recall}: 83\%;
    \item 
    Semantic Score -- дообученный с помощью параметро-эффективного метода LoRA \cite{lora} на собранном наборе данных классификатор семантики, определяющий как сильно сохраняют два предложения одно и то же содержание.
    В качестве изначальных весов взят \texttt{cointegrated/rubert-tiny2}. Качество классификатора: 
    \texttt{Accuracy}: 85\%,
    \texttt{F-1}: 86\%,
    \texttt{Precision}: 91\%,
    \texttt{Recall}: 82\%.
\end{itemize}

\section{Обучение без учителя: Denoising Auto-Encoder}
\input{31-unsupervised-dae}

\section{Guided Generation}
\input{32-gedi}

\section{Parameter-efficient fine-tuning}
\input{33-peft}

\section{Few-Shot LLM}
\input{34-llm}

\section{Результаты}
Результаты метрик по всем проведенным экспериментам представлены в таблице \ref{table:results}, а примеры генераций в приложении \ref{cha:appendix1}.

Можно сделать вывод, что лучше всего показали себя большие языковые модели, способные без какого-либо дообучения на конкретную задачу показывать результат лучше, чем целенаправленно обученные на задачу модели.
Языковые модели прошлого поколения (GPT-3, T-5 и пр.) с помощью параметро-эффективных методов обучения могут показать хороший результат, особенно в случае отсутствия большого набора данных.
Более старые алгоритмы показывают качество генераций намного хуже.

Обучение без учителя и Guided Generation показали лучшие метрики SacreBLEU и METEOR.
Использование предобученных языковых моделей в сочетании с параметро-эффективными методами дообучения и использование собранного параллельного набора данных дало наилучший результат с точки зрения комбинации метрик Style Score и Semantic Score.
Это подтверждает другие исследования \cite{li2018delete, mir2019evaluating}, что использование метрик, основанных на n-граммах и сравнении с референсами, зачастую не даёт адекватной оценки качества алгоритма.

\begin{table}[ht]
\small
\centering
\caption{Метрики качества исследованных подходов}
\label{table:results}
\begin{tabular}{|p{0.35\textwidth}|c|c|c|c|}
\hline
% \multicolumn{4}{c}{wiki --> lurk / lurk --> wiki}
% Метод & SacreBLEU & METEOR & StyleScore & SemanticScore   \\ \hline \hline
\multirow{2}{*}{Метод} & SacreBLEU & METEOR & StyleScore & SemanticScore   \\ \cline{2-5}
 & \multicolumn{4}{c|}{wiki $\rightarrow$ lurk / lurk $\rightarrow$ wiki} \\ \hline \hline
Unsupervised DAE & 40,5/38,8 & 0,6/0,59 & 0,22/0,6 & 0,82/0,78 \\\hline
Guided Generation & 12,7/6,7 & 0,35/0,27 & 0,13/0,72 & 0,81/0,75 \\\hline
LoRA(ruT5-paraphraser) & 3,04/3,35 & 0,25/0,26 & 0,3/0,75 & 0,79/0,8 \\\hline
P-Tuning (GPT) & 3,16/4,56 & 0,23/0,23 & 0,56/0,92 & 0,73/0,78 \\\hline
\end{tabular}
\end{table}

Также обратим внимание, что с точки зрения StyleScore задача трансфера стиля из формального вики в неформальный лурк является намного более сложной задачей, с которой во всех рассмотренных методах наблюдаются трудности.
Как было упомянуто в параграфе \ref{cha:analysis:sec:datasets} перефразирование в неформальный стиль является более трудной задачей даже для человека.
Стилистическая специфика лурка более сложна и модели труднее её выучить, нежели формальный стиль Википедии.


% \begin{equation}
%     \frac{i + s + d}{n},
%     \label{lev_eq}
% \end{equation}
% \par где $i$ -- количество вставок;
% \par $s$ -- количество замен;
% \par $d$ -- количество удалённых символов;
% \par $n$ -- количество символов/слов в целевой последовательности.
